services:
  prefect-server:
    image: prefecthq/prefect:3.6.8-python3.13
    container_name: mlops-prefect
    ports:
      - "${PREFECT_PORT:-4200}:4200"
    command: prefect server start --host 0.0.0.0 --port 4200
    env_file:
      - .env
    volumes:
      - prefect-db:/root/.prefect
    networks:
      - mlops-network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:4200/api/health')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  mlflow-server:
    image: ${ECR_MLFLOW_IMAGE}
    container_name: mlops-mlflow
    ports:
      - "${MLFLOW_PORT:-5000}:5000"
    env_file:
      - .env
    volumes:
      - mlflow-db:/app/mlflow.db
      - mlruns:/app/mlruns
    networks:
      - mlops-network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:5000/health')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  train:
    image: ${ECR_TRAIN_IMAGE}
    container_name: mlops-train
    env_file:
      - .env
    volumes:
      - data:/app/data
      - models:/app/models
      - mlflow-db:/app/mlflow.db
      - mlruns:/app/mlruns
    networks:
      - mlops-network
    depends_on:
      prefect-server:
        condition: service_healthy
      mlflow-server:
        condition: service_healthy
    restart: "no"
    # command: python -m src.utils.pipelines

  monitor:
    image: ${ECR_MONITOR_IMAGE}
    container_name: mlops-monitor
    env_file:
      - .env
    volumes:
      - data:/app/data
      - models:/app/models
      - mlflow-db:/app/mlflow.db
      - mlruns:/app/mlruns
    networks:
      - mlops-network
    depends_on:
      prefect-server:
        condition: service_healthy
      mlflow-server:
        condition: service_healthy
      train:
        condition: service_started
    restart: "no"

  api:
    image: ${ECR_API_IMAGE}
    container_name: mlops-api
    ports:
      - "${API_PORT:-8081}:8081"
    env_file:
      - .env
    volumes:
      - data:/app/data
      - models:/app/models
      - mlflow-db:/app/mlflow.db
      - mlruns:/app/mlruns
    networks:
      - mlops-network
    depends_on:
      mlflow-server:
        condition: service_healthy
    restart: unless-stopped

  dashboard:
    image: ${ECR_DASHBOARD_IMAGE}
    container_name: mlops-dashboard
    ports:
      - "${DASHBOARD_PORT:-8501}:8501"
    env_file:
      - .env
    volumes:
      - data:/app/data
      - models:/app/models
      - mlflow-db:/app/mlflow.db
      - mlruns:/app/mlruns
    networks:
      - mlops-network
    depends_on:
      mlflow-server:
        condition: service_healthy
    restart: unless-stopped

volumes:
  prefect-db:
  mlflow-db:
  mlruns:
  models:
  data:

networks:
  mlops-network:
    driver: bridge

