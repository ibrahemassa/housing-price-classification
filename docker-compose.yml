services:
  prefect-server:
    image: prefecthq/prefect:3.6.8-python3.13
    container_name: mlops-prefect
    ports:
      - "${PREFECT_PORT:-4200}:4200"
    command: prefect server start --host 0.0.0.0 --port 4200
    env_file:
      - .env
    volumes:
      - prefect-db:/root/.prefect
    networks:
      - mlops-network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:4200/api/health')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  mlflow-server:
    image: ${ECR_MLFLOW_IMAGE}
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    container_name: mlops-mlflow
    working_dir: /app
    ports:
      - "${MLFLOW_PORT:-5000}:5000"
    env_file:
      - .env
    volumes:
      - ./mlflow.db:/app/mlflow.db
      - ./mlruns:/app/mlruns
    # command: >
    #   sh -c "pip install --no-cache-dir mlflow &&
    #          mlflow server --host 0.0.0.0 --port 5000
    #          --backend-store-uri sqlite:///mlflow.db
    #          --default-artifact-root file:./mlruns"
    networks:
      - mlops-network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:5000/')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped

  train:
    image: ${ECR_TRAIN_IMAGE}
    build:
      context: .
      dockerfile: Dockerfile.train
    container_name: mlops-train
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./mlflow.db:/app/mlflow.db
      - ./mlruns:/app/mlruns
    env_file:
      - .env
    networks:
      - mlops-network
    depends_on:
      prefect-server:
        condition: service_healthy
      mlflow-server:
        condition: service_healthy
    restart: "no"
    # command: python -m src.utils.pipelines

  monitor:
    image: ${ECR_MONITOR_IMAGE}
    build:
      context: .
      dockerfile: Dockerfile.monitor
    container_name: mlops-monitor
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./mlflow.db:/app/mlflow.db
      - ./mlruns:/app/mlruns
    env_file:
      - .env
    networks:
      - mlops-network
    depends_on:
      prefect-server:
        condition: service_healthy
      mlflow-server:
        condition: service_healthy
      train:
        condition: service_started
    restart: "no"

  api:
    image: ${ECR_API_IMAGE}
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: mlops-api
    ports:
      - "${API_PORT:-8081}:8081"
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./mlflow.db:/app/mlflow.db
      - ./mlruns:/app/mlruns
    env_file:
      - .env
    networks:
      - mlops-network
    depends_on:
      mlflow-server:
        condition: service_healthy
    restart: "no"

  dashboard:
    image: ${ECR_DASHBOARD_IMAGE}
    build:
      context: .
      dockerfile: Dockerfile.dashboard
    container_name: mlops-dashboard
    ports:
      - "${DASHBOARD_PORT:-8501}:8501"
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./mlflow.db:/app/mlflow.db
      - ./mlruns:/app/mlruns
    env_file:
      - .env
    networks:
      - mlops-network
    depends_on:
      mlflow-server:
        condition: service_healthy
    restart: unless-stopped

volumes:
  prefect-db:

networks:
  mlops-network:
    driver: bridge
